plot(jitter(child,4) ~ parent, galton)
lm(child ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col= "red")
summary(regrline)
swirl()
summary(spraymodel)
head(InsectSprays)
sprayA <- InsectSprays$spray == "A"
length(sprayA)
length(InsectSprays$spray)
sprayB <- InsectSprays$spray == "B"
spraymodel <- glm(InsectSprays$count ~ as.numeric(sprayA) + as.numeric(sprayB), family = "poisson")
summary(spraymodel)
exp(summary(spraymodel$coef))
summary(spraymodel$coef)
summary(spraymodel$Coefficients)
names(spraymodel)
exp(summary(spraymodel$coefficients))
spraymodel$coefficients
exp(spraymodel$coef)
spraymodel <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson")
summary(spraymodel)
exp(spraymodel$coef)
spraymodel <- glm(InsectSprays$count ~ InsectSprays$spray, family = "poisson")
exp(spraymodel$coef)
?knot
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots <- seq(0, 4*pi, length = 20)
knots
knotmodel <- lm(y ~ cbind(x, 0))
summary(knotmodel)
plot(y~x)
abline(knotmodel)
sapply(knots, function(knot) (x>knot)*(x-knot))
splineTerms(sapply(0, function(k) (k >0) * k))
splineTerms <- sapply(0, function(k) (k >0) * k)
knotmodel <- lm(y ~ cbind(x, splineTerms))
abline(knotmodel)
knotmodel <- predict(lm(y ~ cbind(x, splineTerms)))
abline(knotmodel)
splineTerms
knotmodel <- predict(lm(y ~ x + x[x<0] + x[x>0]))
x2 <- if(x > 0) {x} else {0}
x2 <- for(i in 1:length(x)) {if x[i] > 0 {x[i]} else {0}}
x2 <- for(i in 1:length(x)) {if(x[i] > 0) {x[i]} else {0}}
x2
x2 <- for(i in 1:length(x)) {if(x[i] > 0) {x2[i] <- x[i]} else {x2[i] <- 0}}
x2
x2 <- sapply(x, function(k) (k>0)*k)
x2
x3 <- sapply(x, function(k) (k>0)*k)
x3
x3 <- sapply(x, function(k) (k<0)*k)
x3
knotmodel <- predict(lm(y ~ x + x2 + x3))
abline(knotmodel)
summary(knotmodel)
knotmodel <- lm(y ~ x + x2 + x3)
summary(knotmodel)
abline(knotmodel)
knotmodel <- lm(y ~ cbind(1,x,x2,x3) - 1)
abline(knotmodel)
summary(knotmodel)
install.pacakge("caret")
install.pacakges("caret")
?install.packages
install.packages("caret")
?read.csv
?downloadfile
?download.file
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "training.csv", method = "curl")
download.file(https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv, destfile = "training.csv", method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "training.csv", method = curl)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "training.csv")
training <- read.csv("training.csv")
summary(training)
levels(training$classe)
str(training)
var(1:10)
3dice <- array(1:10, 1:10, 1:10)
threedice <- array(1:10, 1:10, 1:10)
head(threedice)
str(threedice)
threedice[1,1,1]
?array
remove(threedice)
array(1:10, dim = 3)
prac <- array(1:24, dim = c(3,4,2))
prac
exp10s(2,1)
exp10s(4,2)
exp10s(6,2)
exp10s(6,2)
exp10s(6,2)
exp10s(6,2)
exp10s(6,2)
remove(x)
remove(x2)
remove(x3)
remove(y)
x = c(1:10)
y = c(1:10)
z = c(1:10)
threedice <- array(data = max(x,y,z), dim = c(10, 10, 10))
head(threedice)
threedice <- array(data = max(x,y,z)[x,y,z], dim = c(10, 10, 10))
x = matrix(c(1:10, 1:10, 1:10), dim = (3,10))
?matrix
x = matrix(c(1:10, 1:10, 1:10), nrow = 3, ncol = 10)
x
inTrain <- createDataPartition(y = training$classe, p = .6, list = FALSE)
install.packages("caret")
library(caret)
inTrain <- createDataPartition(y = training$classe, p = .6, list = FALSE)
training2 <- training[inTrain,]
testing <- training[-inTrain,]
head(inTrain)
?complete.cases
?transpose
complete.training <- complete.cases(training23)
complete.training <- complete.cases(training2)
sum(complete.training)
complete.training <- training2[, is.na(training[1,])]
str(complete.training)
complete.training <- training2[, !is.na(training[1,])]
str(complete.training)
preComp <- preProcess(complete.training[,-93]), method = "pca", pcaComp = 4)
preComp <- preProcess(complete.training[,-93], method = "pca", pcaComp = 4)
preComp <- preProcess(as.numeric(complete.training[,-93]), method = "pca", pcaComp = 4)
class(complete.training[,2])
class(complete.training[,])
class(complete.training[,1:93])
is.numeric(complete.training[,1])
sapply(complete.training, is.numeric())
sapply(complete.training, function(x) is.numeric(x))
complete.training <- complete.training[,sapply(complete.training, function(x) is.numeric(x))]
preComp <- preProcess(complete.training, method = "pca", pcaComp = 4)
plot(preComp[,1], preComp[,2], col = typeColor)
curlPC <- predict(preComp)
curlPC <- predict(preComp, newdata = training[,classe])
curlPC <- predict(preComp, newdata = training$classe)
sum(is.na(training$classe))
?predict
curlPC <- predict(preComp, complete.training)
plot(curlPC[,1],curlPC[,2],col=typeColor)
plot(curlPC[,1],curlPC[,2])
plot(curlPC[,1],curlPC[,2], col = classe)
plot(curlPC[,1],curlPC[,2], col = training$classe)
?predict
qplot(curlPC[,1], curlPC[,2], color = training$classe)
qplot(curlPC[,1], curlPC[,2], colour = training$classe)
length(curlPC[,1])
qplot(curlPC[,1], curlPC[,2], color = complete.training$classe)
qplot(curlPC[,1], curlPC[,2], colour = complete.training$classe)
levels(complete.training$classe)
class(complete.training$classe)
length(training$classe)
qplot(curlPC[,1], curlPC[,2], colour = training2$classe)
qplot(curlPC[,3], curlPC[,4], colour = training2$classe)
preComp <- preProcess(complete.training, method = "pca", pcaComp = 2)
curlPC <- predict(preComp, complete.training)
qplot(curlPC[,1], curlPC[,2], colour = training2$classe)
curlPC2 <- train(training2$classe ~ complete.training, method = "pca")
class(complete.training)
curlPC2 <- train(training2$classe ~ preComp, method = "pca")
class(preComp)
class(curlPC)
curlPC2 <- train(training2 ~ . , method = "pca")
curlPC2 <- train(classe ~ . , data = training2, method = "pca")
curlPC2 <- train(classe ~ . , data = training2, method = "glm")
install.packages("e1071")
curlPC2 <- train(classe ~ . , data = training2, method = "glm")
warnings()
completeClasse <- rbind(complete.training, training2$classe)
head(completeClasse$classe)
completeClasse <- cbind(complete.training, training2$classe)
head(completeClasse$classe)
head(training2$classe)
names(completeClasse)
completeClasse[,57] <- "classe"
head(completeClasse$classe)
completeClasse <- cbind(complete.training, training2$classe)
?colnames
colnames(completeClasse[,57]) <- "classe"
colnames(completeClasse)[57] <- "classe"
head(completeClasse$classe)
curlPC2 <- train(classe ~ . , data = completeClasse, method = "glm")
?train
str(training)
curlAvs <- aggregate(training2, by = classe)
curlAvs <- aggregate(training2, by = classe, FUN = mean)
curlAvs <- aggregate(training2, by = training2$classe, FUN = mean)
curlAvs <- aggregate(training2 ~ classe, FUN = mean)
curlAvs <- aggregate(training2[,-93] ~ classe, data = training2, FUN = mean)
class(training2[,-93])
curlAvs <- aggregate(complete.training ~ training2$classe, FUN = mean)
curlAvs <- aggregate(complete.training$yaw_dumbbell ~ training2$classe, FUN = mean)
curlAvs
curlAvs <- aggregate(complete.training[,-93] ~ training2$classe, FUN = mean)
20000*160
aggregate(complete.training$magnet_arm_z ~ training2$classe, FUN = mean)
preComp <- preProcess(complete.training, pcaComp = 2)
curlPC <- predict(preComp, complete.training)
qplot(curlPC[,1], curlPC[,2], colour = training2$classe)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
head(vowel.train)
set.seed(33833)
?train
library(caret)
?train
vowelrf <- train(y ~ ., data = vowel.train[,-1], method = "rf")
vowelrf <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
vowelgbm <- train(y ~ ., data = vowel.train, method = "gbm", verbose = FALSE)
vowelrf
predict(vowelrf, vowel.test[,1])
predict(vowelrf, vowel.test)
rfpred <- predict(vowelrf, vowel.test)
table(rfpred, vowel.test$y)
confusionMatrix(rfpred, vowel.test$y)
foo <- rfpred==vowel.test$y
foo
table(rfpred, vowel.test$y)
gbmpred <- predict(vowelgbm, vowel.test)
vowelrf
str(vowelrf)
rfvowel$finalModel
vowelrf$finalModel
head(vowel.train)
?transform
transform(vowel.train, y = as.factor(y))
vowel.train <- transform(vowel.train, y = as.factor(y))
vowelrf <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
vowelgbm <- train(y ~ ., data = vowel.train, method = "gbm", verbose = FALSE)
vowel.test <- transform(vowel.test, y = as.factor(y))
class(vowel.test$y)
rfpred <- predict(vowelrf, vowel.test)
table(rfpred, vowel.test$y)
sum(rfpred$diagonal)
diagonal(rfpred)
confusionMatrix(rfpred, vowel.test$y)
confusionMatrix(gbmpred, vowel.test$y)
gbmpred <- predict(vowelgbm, vowel.test)
confusionMatrix(gbmpred, vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
head(AlzheimerDisease)
head(adData)
alzrf <- train(diagnosis ~ ., data = adData, method = "rf")
alzgbm <- train(diagnosis ~ ., data = adData, method = "gbm", verbose = FALSE)
alzlda <- train(diagnosis ~ ., data = adData, method = "lda")
set.seed(62433)
alzrf <- train(diagnosis ~ ., data = adData, method = "rf")alzgbm <- train(diagnosis ~ ., data = adData, method = "gbm", verbose = FALSE)
> alzlda <- train(diagnosis ~ ., data = adData, method = "lda")
alzrf <- train(diagnosis ~ ., data = training, method = "rf")
alzgbm <- train(diagnosis ~ ., data = training, method = "gbm", verbose = FALSE)
alzlda <- train(diagnosis ~ ., data = training, method = "lda")
alzrfpred <- predict(alzrf, testing)
alzgbmpred <- predict(alzrf, testing)
alzgbmpred <- predict(alzgbm, testing)
alzldapred <- predict(alzlda, testing)
?accuracy
class(alzrfpred)
class(confusionMatrix(alzrfpred, testing$diagnosis))
class(confusionMatrix(alzrfpred, testing$diagnosis))[1]
confusionMatrix(alzrfpred, testing$diagnosis)[1]
confusionMatrix(alzrfpred, testing$diagnosis)[[1]]
confusionMatrix(alzrfpred, testing$diagnosis)$OverallStatistics
confusionMatrix(alzrfpred, testing$diagnosis)
confusionMatrix(alzgbmpred, testing$diagnosis)
confusionMatrix(alzldapred, testing$diagnosis)
predDF <- data.frame(alzrfpred, alzgbmpred, alzldapred, diagnosis = testing$diagnosis)
combMod <- train(diagnosis ~ ., method = "gam", data=predDF)
combPred <- predict(combMod, predDF)
confusionMatrix(combPred, predDF$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
head(concrete)
concreteMod <- train(CompressiveStrength ~ ., data = training, method = "lasso")
?plot.enet
plot.enet(concreteMod)
?enet
concreteMod
plot(enet(training$CompressiveStrength, y=training[,-9]), xvar = "penalty")
enet(training$CompressiveStrength, y = training[,-9])
enet(training$CompressiveStrength, y = training[,-9], lambda = 0)
plot(enet(y = training$CompressiveStrength, x=training[,-9], lambda = 0), xvar = "penalty")
enet(y = training$CompressiveStrength, x=training[,-9], lambda = 0)
?enet
enet(y = training$CompressiveStrength, x=training, lambda = 0)
enet(y = training$CompressiveStrength, x=training[,-9])
enet(y = training$CompressiveStrength, x=training[,-9], lambda = 1)
install.packages("enet")
library(enet)
install.packages("elasticnet")
plot(concreteMod$finalModel, xvar = "penalty")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", "websitevisits.csv")
webData <- read.csv("websitevisits.csv")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = webData
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecasting")
library(forecast)
install.packages("forecast")
library(forecast)
?bats
head(training)
visitsModel <- bats(visitsTumblr ~ ., data = dat)
visitsModel <- bats(dat)
visitsModel <- bats(date, data = dat)
visitsModel <- bats(dat$date)
visitsModel
predict(visitsModel, testing
)
visitsModel <- bats(tstrain)
predict(visitsModel, testing)
visitsModel
batspred <- predict(visitsModel, ts(testing$visitsTumblr))
plot(forecast(visitsModel))
batspred <- predict(forecast(visitsModel), ts(testing$visitsTumblr))
batspred
testing$visitsTumblr
?forecast
batspred <- forecast(ts(testing$visitsTumblr), level = .95)
batspred
batspred <- forecast(batspred, h=235, level = .95)
head(batspred)
batspred <- forecast(visitsModel, h=235, level = .95)
head(batspred)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(lubridate)  # For year() function below
dat = webData
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
batspred <- bats(tstrain)
plot(forecast(batspred))
forecast(batspred)
head(testing)
max(testing)
max(testing$visitsTumblr)
forecast(batspred, 235)
forecast(batspred, 235)[,6] > testing$visitsTumblr
class(forecast(batspred, 235))
fcast <- forecast(batspred, 235)
accuracy(fcast, testing)
accuracy(fcast, testing$visitsTumblr)
forecast[[6]]
?accuracy
head(forecast[,6])
fcast <- forecast.bats(batspred, 235)
accuracy(fcast, testing$visitsTumblr)
tbats.components(batspred)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
?e1071
library(e1071)
?e1071
svm.model <- svm(CompressiveStrength~., data = training)
predict(svm.model, testing)
conPred <- predict(svm.model, testing)
confusionMatrix(conPred, testing$CompressionStrength)
conPred <- predict(svm.model, testing[,-9])
confusionMatrix(conPred, testing$CompressionStrength)
length(conPred)
length(testing$CompressionStrength)
head(testing)
confusionMatrix(conPred, testing$CompressiveStrength)
length(testing$CompressiveStrength)
confusionMatrix(conPred, testing$CompressiveStrength)
confusionMatrix(conPred, testing$CompressiveStrength)
head(conPred)
head(testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svm.model <- train(CompressiveStrength ~ ., data = training, method = "svm")
svm.model <- svm(CompressiveStrength ~ ., data = training)
svmpred <- predict(svm.model, testing[,-9])
confusionMatrix(svmpred, testing[,9])
levels(svmpred)
level(svmpred)
class(svmpred)
class(testing$CompressiveStrength)
?rmse
sqrt(sum((svmpred-testing$CompressiveStrength)^2))
sqrt(sum((svmpred-testing$CompressiveStrength)^2)/256)
?forecast
library(forecast)
?forecast
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", "gaData,csv")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", "gaData.csv")
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
batsmod <- bats(tstrain)
forecast(tstrain, h = 235, level = .95)
fcast <- forecast(tstrain, h = 235, level = .95)
fitted.values(fcast)
residuals(fcast)
sum(testing$visitsTumblr > fcast$upper)
sum(testing$visitsTumblr > fcast$upper)/235
sum(testing$visitsTumblr > fcast$upper)/235-1
install.packages("shiny")
library(shiny)
library(manipulate)
myPlot <- function(s) {plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
myPlot
myPlot(5)
myPlot(1)
manipulate(myPlot, s = slider(0,2,step = 0.1))
manipulate(myPlot(s), slider = x(0,2,step = 0.1))
manipulate(myPlot(s), x.s = slider(0,2,step = 0.1))
manipulate(myPlot(s), s = slider(0,2,step = 0.1))
?dTable
install.packages("rCharts")
library(rCharts)
install.packages(rCharts)
?rCharts
install_github("rCharts", "ramnathv")
require(devtools)
install.packages("devtools")
install_github('rCharts', 'ramnathv')
install.packages("rCharts")
library(devtools)
install.packages("Rtools")
install.packages("rtools")
install_github("rCharts", "ramnathv")
require(devtools)
install_github("rCharts", "ramnathv")
library(knitr)
load("//mpr.org/dfs/users/jpeterson-brandt/R Coursera Directory/Capstone/(2).RData")
load("//mpr.org/dfs/users/jpeterson-brandt/R Coursera Directory/Capstone/(2).RData")
remove(InsectSprays)
remove(attenu)
remove(complete.training)
getwd()
setwd("~/R Coursera Directory/Capstone ProjectData/final/en_US")
blogs <- scan("en_US.blogs.txt", character(0), sep = "\n")
twitter <- scan("en_US.twitter.txt", character(0), sep = "\n")
news <- scan("en_US.news.txt", character(0), sep = "\n")
set.seed(8346)
library(caret)
randomTweets <- sample(1:length(twitter), 5000, replace = FALSE)
tweetSample <- twitter[randomTweets]
randomBlogs <- sample(1:length(blogs), 5000, replace = FALSE)
blogSample <- twitter[randomBlogs]
randomNews <- sample(1:length(news), 5000, replace = FALSE)
newsSample <- news[randomNews]
remove(news)
remove(twitter)
remove(blogs)
setwd("~/R Coursera Directory/Capstone")
